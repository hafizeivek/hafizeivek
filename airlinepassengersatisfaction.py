# -*- coding: utf-8 -*-
"""AirlinePassengerSatisfaction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17PfPFOT_aLvHfuOnqQe2TBWNb8-DGTOa
"""

# Sayısal işlemler ve dizi işlemleri için
import numpy as np

# Veri analizi ve veri manipülasyonu için
import pandas as pd

# Grafik çizimleri için temel kütüphane
import matplotlib.pyplot as plt

# İstatistiksel görselleştirmeler için (ısı haritası, boxplot, vs.)
import seaborn as sns

# Grafik yerleşimlerini özelleştirmek için kullanılır (çoklu grafik düzeni)
import matplotlib.gridspec as gridspec

# Matplotlib için renk haritaları (colormap) modülü
from matplotlib import cm
import matplotlib.patches as mpatches

from google.colab import drive

# Google Drive'ı bağla
drive.mount('/content/drive')

# Dosyanın tam yolu
file_path = '/content/drive/MyDrive/havayolu/train.csv'

# CSV dosyasını oku
df = pd.read_csv(file_path)

df.head()  # Varsayılan olarak ilk 5 satırı gösterir

df.info()  # Veri tipi ve eksik değerleri gösterir

df.shape  # (satır sayısı, sütun sayısı)

df.columns

df.describe() # Temel istatistiksel özet

# Eksik değerleri tespit et
missing_values = df.isnull().sum()

# Eksik veri içeren sütunları filtreleyerek sadece eksik değerleri gösterelim
missing_values = missing_values[missing_values > 0]

# Sonucu daha düzenli görüntüleyelim
print("Eksik Değer Sayıları:\n")
print(missing_values)

# Eksik veri yüzdesini hesapla
missing_percentage = (df.isnull().sum() / len(df)) * 100

# Sadece eksik verisi olan sütunları gösterelim
missing_percentage = missing_percentage[missing_percentage > 0]

# Sonucu daha okunaklı hale getirelim
print("Eksik Değer Yüzdeleri (%):\n")
print(missing_percentage.round(2))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap

# Sarı-lacivert özel renk paleti
sari_lacivert = ListedColormap(["#f7dc6f", "#1a237e"])  # sarı ve koyu lacivert

plt.figure(figsize=(12, 6))
sns.heatmap(df.isnull(), cmap=sari_lacivert, cbar=False, yticklabels=False)
plt.title("Eksik Verilerin Dağılımı", fontsize=14)
plt.show()

df.sample(n=5) # veri setinden 5 rastgele satır seçme

# Sayısal değişkenlerin histogramlarını çizme
df.hist(figsize=(12, 8), bins=30,color='#FFE4B5', edgecolor="black")

# Başlık ekleme
plt.suptitle("Sayısal Değişkenlerin Histogramı", fontsize=14)

# Eksen etiketlerinin açılarını değiştirme
plt.xticks(rotation=45)  # x eksenindeki etiketlerin 45 derece döndürülmesi
plt.yticks(rotation=0)   # y eksenindeki etiketlerin yatay olması

# Layout ayarlarını yaparak yazıların üst üste binmesini engelleme
plt.tight_layout()

# Grafiği gösterme
plt.show()

"""hedef dağılımı"""

# Şekli oluştur
fig = plt.figure(figsize=(22, 6))

# Grid sistemi tanımla: 1 satır, 2 sütun
grid = gridspec.GridSpec(nrows=1, ncols=2, figure=fig)

# İlk subplot - Çubuk grafik
ax1 = fig.add_subplot(grid[0, 0])
ax1.set_title('Memnuniyet Durumu Dağılımı')
for index, value in enumerate(df['satisfaction'].value_counts()):
    ax1.annotate(value, xy=(index, value), ha='center', va='center', fontsize=15)


# Farklı pastel tonları (Set2 renk paleti)
renkler = sns.color_palette("Set2", 2)  # Set2 paleti ile iki renk seçimi

# Çubuk grafiği çiz
sns.countplot(x='satisfaction', data=df, ax=ax1, hue='satisfaction', palette=renkler)
ax1.set_xlabel('Yolcu Memnuniyeti')
ax1.set_ylabel('Yolcu Sayısı')

# Açıklama (Türkçe legend)
memnun_patch = mpatches.Patch(color=renkler[0], label='Tarafsız veya Memnuniyetsiz')
memnuniyetsiz_patch = mpatches.Patch(color=renkler[1], label='Memnun')
legend = ax1.legend(handles=[memnun_patch, memnuniyetsiz_patch], loc='upper right', frameon=True)
legend.get_frame().set_facecolor('white')
legend.get_frame().set_edgecolor('black')

# İkinci subplot - Pasta grafik
ax2 = fig.add_subplot(grid[0, 1])
ax2.set_title('Memnuniyet Oranları')

label = list(df['satisfaction'].value_counts().index)
value = list(df['satisfaction'].value_counts().values)
colors = sns.color_palette("Set2", len(label))  # Set2 paleti ile pasta grafiği için renkler

# Pasta grafiğini çiz
ax2.pie(value, labels=label, autopct='%1.1f%%', explode=(0, 0.2), colors=colors, startangle=90)
ax2.axis('equal')  # Daire gibi görünsün

# Göster
plt.tight_layout()
plt.show()

"""yolcu profili"""

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns

# Şekli oluştur
fig = plt.figure(figsize=(20, 12))
plt.suptitle('Yolcu Profili', weight='bold', fontsize=24)

# Grid sistemi tanımla: 2 satır, 2 sütun
grid = gridspec.GridSpec(nrows=2, ncols=2, figure=fig)

# İlk subplot - Cinsiyet
ax1 = fig.add_subplot(grid[0, 0])
ax1.set_title('Cinsiyet')

# Etiketler ve değerler
label = list(df['Gender'].value_counts().index)
value = list(df['Gender'].value_counts().values)

# Pastel renkler
target_colors = ['#FFB3C1', '#A2C2E2']  # Pembe ve mavi pastel tonları

# Pasta grafiği (yarı halka değil, klasik daire)
ax1.pie(value, labels=label, autopct='%1.1f%%', explode=(0, 0.2), startangle=90, colors=target_colors, wedgeprops={'width': 0.3})
ax1.axis('equal')  # Daire gibi görünmesini sağla

# İkinci subplot - Müşteri Türü (Yeni renkler)
ax2 = fig.add_subplot(grid[0, 1])
ax2.set_title('Müşteri Türü', fontsize=18)

# Etiketler ve değerler
label = list(df['Customer Type'].value_counts().index)
value = list(df['Customer Type'].value_counts().values)

# Yeni pastel renkler
target_colors = ['#98FB98', '#8A2BE2']  # Turuncu ve mor pastel tonları

# Tam pasta grafiği (kenarlık olmadan)
ax2.pie(value, labels=label, autopct='%1.1f%%', explode=(0, 0.2), startangle=90, colors=target_colors)
ax2.axis('equal')

# Üçüncü subplot - Yatay Çubuk Grafik (Yeni renkler)
ax3 = fig.add_subplot(grid[1, 0])
ax3.set_title('Sınıf', fontsize=18)

# Etiketler ve değerler
label = list(df['Class'].value_counts().index)
value = list(df['Class'].value_counts().values)

# Yeni pastel renkler
target_colors = ['#FFDAB9', '#E0BBE4', '#57DBDB']  # Açık yeşil, pembe ve altın sarısı

# Yatay çubuk grafik (kenar çizgileri kaldırıldı ve biraz daha aşağıya alındı)
ax3.barh(label, value, color=target_colors, edgecolor='none')

# Yatay eksen etiketleri
ax3.set_xlabel('Frekans')

# Dördüncü subplot - Yaş Dağılımı (KDE grafiği)
ax4 = fig.add_subplot(grid[1, 1])
ax4.set_title('Yaş Dağılımı', fontsize=18)

# KDE grafiği
sns.kdeplot(df['Age'], ax=ax4, fill=True, color='#FF69B4')

ax4.tick_params(axis='x', labelsize=20)
ax4.tick_params(axis='y', labelsize=20)
ax4.set_xlabel('Yaş', fontsize=20)
ax4.set_ylabel('Yoğunluk', fontsize=20)

for spine in ax4.spines.values():
  spine.set_visible(False)

ax4.axvline(df['Age'].mean(),linestyle='--', color='red', label='Ortalama Yaş')
ax4.legend(fontsize=20)

# Tüm grafikleri göster
plt.tight_layout()
plt.show()
# Grafik göster
plt.tight_layout(pad=4.0)  # Bu, grafiğin arasındaki boşluğu arttırır

# Grafik göster
plt.show()

"""insanların memnuniyet seviyesi"""

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns

# Renk paletleri
renk_paleti = {
    'satisfied': '#A1D490',         # Daha belirgin yeşil
    'neutral or dissatisfied': '#BA89C2'  # Hafif koyu leylak
}
renk_paleti_class = {
    'satisfied': '#FFDAB9',         # Şeftali
    'neutral or dissatisfied': '#FADADD'  # Açık gül rengi
}
renk_paleti_travel = {
    'satisfied': '#ADD8E6',         # Soluk mavi (yeni)
    'neutral or dissatisfied': '#FFB6C1'  # Soluk pembe (yeni)
}
renk_paleti_customer_type = {
    'satisfied': '#90EE90',         # Açık yeşil
    'neutral or dissatisfied': '#FFCCCB'  # Soluk kırmızı
}

# Şekil ve başlık
fig = plt.figure(figsize=(30, 18))
plt.suptitle('Yolcu Profili', weight='bold', fontsize=24)

# Grid alanı
grid = gridspec.GridSpec(nrows=2, ncols=2, figure=fig)

# 1. Grafik - Cinsiyet Dağılımı
ax1 = fig.add_subplot(grid[0, 0])  # grid[0, :1] yerine grid[0, 0]
ax1.set_title('Cinsiyet Dağılımı', fontsize=22)
sns.countplot(x=df['Gender'], hue=df['satisfaction'], ax=ax1, palette=renk_paleti)

# Sayı etiketleri
for p in ax1.patches:
    height = p.get_height()
    if height > 0:
        ax1.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax1.get_yaxis().set_visible(False)
for spine in ax1.spines.values():
    spine.set_visible(False)

ax1.tick_params(axis='x', labelsize=15)
ax1.set_xlabel('Cinsiyet', fontsize=20)

# 2. Grafik - Sınıf Dağılımı
ax2 = fig.add_subplot(grid[0, 1])
ax2.set_title('Sınıf Dağılımı', fontsize=22)
sns.countplot(x=df['Class'], hue=df['satisfaction'], ax=ax2, palette=renk_paleti_class)

# Sayı etiketleri
for p in ax2.patches:
    height = p.get_height()
    if height > 0:
        ax2.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax2.get_yaxis().set_visible(False)
for spine in ax2.spines.values():
    spine.set_visible(False)

ax2.tick_params(axis='x', labelsize=15)
ax2.set_xlabel('Sınıf', fontsize=20)

# 3. Grafik - Seyahat Dağılımı
ax3 = fig.add_subplot(grid[1, :1])  # grid[1, :1] seçilerek 3. grafik alt bölümde yerleştirildi
ax3.set_title('Seyahat Dağılımı', fontsize=22)

# Seyahat türü üzerine countplot
sns.countplot(x=df['Type of Travel'], hue=df['satisfaction'], ax=ax3, palette=renk_paleti_travel)

# Sayı etiketleri
for p in ax3.patches:
    height = p.get_height()
    if height > 0:
        ax3.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax3.get_yaxis().set_visible(False)
for spine in ax3.spines.values():
    spine.set_visible(False)

ax3.tick_params(axis='x', labelsize=15)
ax3.set_xlabel('Seyahat Türü', fontsize=20)

# 4. Grafik - Müşteri Tipi ve Tatmin Durumu (Yeni renkler ile)
ax4 = fig.add_subplot(grid[1, 1])  # 4. grafik için yer ekleniyor
ax4.set_title('Müşteri Tipi ve Tatmin Durumu', fontsize=22)

# Yeni renk paleti ile müşteri tipi ve tatmin durumu üzerine countplot
sns.countplot(x=df['Customer Type'], hue=df['satisfaction'], ax=ax4, palette=renk_paleti_customer_type)

# Sayı etiketleri
for p in ax4.patches:
    height = p.get_height()
    if height > 0:
        ax4.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax4.get_yaxis().set_visible(False)
for spine in ax4.spines.values():
    spine.set_visible(False)

ax4.tick_params(axis='x', labelsize=15)
ax4.set_xlabel('Müşteri Tipi', fontsize=20)

# Grafik göster
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Veriyi oku
data = pd.read_csv("/content/drive/MyDrive/havayolu/train.csv")

# 2. Grafik çizimi (renkler özelleştirildi)
with sns.axes_style('white'):
    g = sns.catplot(
        x="Age",
        data=data,
        aspect=3.0,
        kind='count',
        hue='satisfaction',
        palette=['pink', 'skyblue'],
        order=range(5, 80)
    )

    # 3. Eksen etiketleri ve başlık
    g.set_ylabels('Yolcu Sayısı')
    g.set_xlabels('Yaş')
    g.fig.suptitle('Yolcu Yaş Dağılımı ve Memnuniyet', fontsize=16)

# 4. Grafiği göster
plt.show()

"""

visualize the ordinal data"""

df.columns

num_var=df.select_dtypes(include=['int']).columns[3:]
num_var

df['Ease of Online booking'].value_counts()

ordinal_dict={
    5: 'Excellent',
    4: 'Very Good',
    3: 'Good',
    2: 'Bad',
    1: 'Very Bad',
    0:'Not Reported'
}
df['Ease of Online booking']=df['Ease of Online booking'].map(ordinal_dict)

df['Ease of Online booking'].value_counts()

def CalPercentage(df, col):
    percent_df = df[col].value_counts(normalize=True).mul(100).reset_index()
    percent_df.columns = [col, 'per']
    return percent_df

CalPercentage(df, 'Ease of Online booking')

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Ordinal dict
ordinal_dict = {
    5: 'Excellent',
    4: 'Very Good',
    3: 'Good',
    2: 'Bad',
    1: 'Very Bad',
    0: 'Not Reported'
}

# Yüzde hesaplama fonksiyonu
def CalPercentage(df, col):
    # Verilen sütunun yüzdesel dağılımını hesaplama
    percentage = df[col].value_counts(normalize=True) * 100
    df_per = pd.DataFrame({col: percentage.index, 'per': percentage.values})
    return df_per

def Visualization(df, col):
    # Belirtilen sütunun yüzde dağılımını hesapla
    df_per = CalPercentage(df, col)

    # 1 satır 2 sütundan oluşan bir figür (grafik alanı) oluştur
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 6))

    # Grafiğe genel bir başlık ekle
    plt.suptitle(col, fontsize=24, weight='bold')

    # Alt grafikler arası boşluğu ayarla
    plt.subplots_adjust(hspace=0.9)

    # İlk grafik: Kategorik sütunun yüzdelik dağılımını gösteren barplot
    pastel_palette = sns.color_palette("pastel", n_colors=len(df_per))  # Pastel renk paleti
    sns.barplot(x=df_per[col], y='per', data=df_per, ax=ax1, palette=pastel_palette)

    # İkinci grafik: Aynı sütunun memnuniyet durumuna göre countplot’u
    sns.countplot(x=col, data=df, hue='satisfaction', ax=ax2, order=ordinal_dict.values(), palette=pastel_palette)

    # Barplot için x ekseni etiketlerini ayarla ve döndür
    ax1.set_xticklabels(df_per[col], rotation=45)

    # Barplot için x ekseni başlığı
    ax1.set_xlabel('Experience', fontsize=20)

    # Barplot’un y eksenini görünmez yap
    ax1.get_yaxis().set_visible(False)

    # Countplot için x ekseni başlığı
    ax2.set_xlabel(col, fontsize=20)

    # Countplot için x ekseni etiketlerini döndür
    ax2.set_xticklabels(ordinal_dict.values(), rotation=45)

    # Countplot’un y eksenini gizle
    ax2.get_yaxis().set_visible(False)

    # Her iki grafik için kenar çerçevelerini (spine) gizle
    for spine1, spine2 in zip(ax1.spines.values(), ax2.spines.values()):
        spine1.set_visible(False)
        spine2.set_visible(False)

    # Grafiklerin tümünü göster
    plt.show()

Visualization(df, 'Ease of Online booking')

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Ordinal dict
ordinal_dict = {
    5: 'Excellent',
    4: 'Very Good',
    3: 'Good',
    2: 'Bad',
    1: 'Very Bad',
    0: 'Not Reported'
}

# Yüzde hesaplama fonksiyonu (Kolonun her bir değeri için)
def CalPercentage(df, col):
    counts = df[col].value_counts()
    percents = df[col].value_counts(normalize=True) * 100
    df_per = pd.DataFrame({'count': counts, 'per': percents})
    return df_per

def Visualization(df, col):
    # Kolondaki benzersiz değerleri kontrol et
    print(f"Benzersiz değerler: {df[col].unique()}")

    # Ordinal dönüşümünü yap
    df[col] = df[col].map(ordinal_dict)

    # Kolondaki 'NaN' değerleri kontrol et
    if df[col].isnull().any():
        print(f"{col} kolonunda eksik (NaN) değerler var. Bunları 'Not Reported' olarak işliyoruz.")
        df[col] = df[col].fillna('Not Reported')

    # Ordinal kategorilerin sıralanması
    df[col] = pd.Categorical(df[col], categories=ordinal_dict.values(), ordered=True)

    # Yüzdelik dağılımı hesapla
    df_per = CalPercentage(df, col)

    # 1 satır 2 sütundan oluşan bir figür (grafik alanı) oluştur
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 6))

    # Grafiğe genel bir başlık ekle
    plt.suptitle(col, fontsize=24, weight='bold')

    # Alt grafikler arası boşluğu ayarla
    plt.subplots_adjust(hspace=0.9)

    # İlk grafik: Kategorik sütunun yüzdelik dağılımını gösteren barplot
    pastel_palette = sns.color_palette("pastel", n_colors=len(df_per))  # Pastel renk paleti

    # Barplot’u metin etiketleri ile oluştur
    sns.barplot(x=df_per.index, y='per', data=df_per, ax=ax1, palette=pastel_palette)

    # İkinci grafik: Aynı sütunun memnuniyet durumuna göre countplot’u
    pastel_palette = sns.color_palette("pastel", n_colors=2)  # 2 renk

    # Memnuniyet durumuna göre countplot çiziyoruz
    sns.countplot(x=col, data=df, hue='satisfaction', ax=ax2,
                  order=ordinal_dict.values(), palette=pastel_palette)

    # Barplot için x ekseni etiketlerini ayarla ve döndür
    ax1.set_xticklabels(ordinal_dict.values(), rotation=45)

    # Barplot için x ekseni başlığı
    ax1.set_xlabel('Experience', fontsize=20)

    # Barplot’un y eksenini görünmez yap
    ax1.get_yaxis().set_visible(False)

    # Countplot için x ekseni başlığı
    ax2.set_xlabel(col, fontsize=20)

    # Countplot için x ekseni etiketlerini döndür
    ax2.set_xticklabels(ordinal_dict.values(), rotation=45)

    # Countplot’un y eksenini gizle
    ax2.get_yaxis().set_visible(False)

    # Her iki grafik için kenar çerçevelerini (spine) gizle
    for spine1, spine2 in zip(ax1.spines.values(), ax2.spines.values()):
        spine1.set_visible(False)
        spine2.set_visible(False)

    # Grafiklerin tümünü göster
    plt.show()

# Test için tek bir sütun üzerinden kontrol edelim
columns = [
    'Inflight wifi service', 'Gate location', 'Food and drink', 'Online boarding',
    'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service',
    'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness'
]

# Her bir sütun için Visualization fonksiyonunu çalıştırma
for col in columns:
    Visualization(df, col)

"""outlier detection techniques"""

['Flight Distance','Departure Delay in Minutes', 'Arrival Delay in Minutes']

np.percentile(df['Flight Distance'],25)
np.percentile(df['Flight Distance'],75)
iqr=np.percentile(df['Flight Distance'],75)-np.percentile(df['Flight Distance'],25)
upper_limit=np.percentile(df['Flight Distance'],75)+1.5*iqr
lower_limit=np.percentile(df['Flight Distance'],25)-1.5*iqr
print(lower_limit, upper_limit)

import matplotlib.pyplot as plt
import seaborn as sns

# Grafik oluştur
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
plt.suptitle('Flight Distance Analysis', fontsize=24, weight='bold')

# Box-Plot
ax1.set_title('Box-Plot', fontsize=15)
sns.boxplot(y='Flight Distance', data=df, ax=ax1)
ax1.set_ylabel('Flight Distance', fontsize=20)

# KDE-Plot
ax2.set_title('KDE-Plot', fontsize=15)
sns.kdeplot(x='Flight Distance', data=df, ax=ax2, fill=True, color='#5e597e')

# Sınır çizgileri
ax2.axvline(x=lower_limit, linestyle='--', color='#06550e', label='Lower Bound')
ax2.axvline(x=upper_limit, linestyle='--', color='#cc1111', label='Upper Bound')
ax2.legend()

# Etiket ve açıklama
ax2.set_xlabel('Flight Distance', fontsize=20)
ax2.annotate(f'{upper_limit:.0f}',
             xy=(upper_limit, 0.0005),
             arrowprops=dict(arrowstyle='->', color='r', alpha=0.8))

plt.show()

def percentile_ate_first_view(data, col, start, end, jump):
    for i in range(start, end, jump):
        var = data[col].values
        var = np.sort(var, axis=None)
        print("{} percentile value is {}".format(i, var[int(len(var)*(float(i)/100))]))
    print("100 percentile value is ", var[-1])

percentile_ate_first_view(df, 'Flight Distance',0,100,10)

percentile_ate_first_view(df,'Flight Distance',90,100,1)

def percentile_ate_third_view(data, col):
    for i in np.arange(0.0,1.0,0.1):
        var = data[col].values
        var = np.sort(var, axis=None)
        print("{} percentile value is {}".format(99+i, var[int(len(var)*(float(99+i)/100))]))
    print("100 percentile value is ", var[-1])

percentile_ate_third_view(df, 'Flight Distance')

df[df['Flight Distance']>3995]

def OutlierDetection(data, col):
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np

    # IQR hesaplama
    q1 = np.percentile(data[col], 25)
    q3 = np.percentile(data[col], 75)
    iqr = q3 - q1
    lower_bound = q1 - (1.5 * iqr)
    upper_bound = q3 + (1.5 * iqr)

    # Grafik alanları oluştur
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    plt.suptitle(f'{col} Analysis', fontsize=24, weight='bold')

    # Boxplot
    ax1.set_title('Box-Plot', fontsize=15)
    sns.boxplot(y=col, data=data, ax=ax1, flierprops={"marker": "x"})
    ax1.set_ylabel(col, fontsize=20)
    ax1.get_yaxis().set_visible(False)

    # KDE Plot
    ax2.set_title('KDE-Plot', fontsize=15)
    sns.kdeplot(x=data[col], ax=ax2, fill=True, color='#5e597e')
    ax2.axvline(data[col].mean(), linestyle='--', color='#ff4000', label='Mean')
    ax2.axvline(data[col].median(), linestyle='--', color='#4000aa', label='Median')
    ax2.axvline(lower_bound, linestyle='--', color='#06550e', label='Lower Bound')
    ax2.axvline(upper_bound, linestyle='--', color='#1c1111', label='Upper Bound')
    ax2.legend()
    ax2.set_xlabel(col, fontsize=20)
    ax2.annotate(f'{upper_bound:.0f}', xy=(upper_bound, 0.04),
                 arrowprops=dict(arrowstyle='->', color='r', alpha=0.8),
                 fontsize=12)

    plt.tight_layout()
    plt.show()
OutlierDetection(df, 'Departure Delay in Minutes')

percentile_ate_first_view(df,'Departure Delay in Minutes',0,100,10)

percentile_ate_first_view(df,'Departure Delay in Minutes',90,100,1)

percentile_ate_third_view(df,'Departure Delay in Minutes')

var = df['Departure Delay in Minutes'].values
var = np.sort(var, axis=None)
plt.plot(var[-40:-5])

df[df['Departure Delay in Minutes']>750]

OutlierDetection(df, 'Arrival Delay in Minutes')

percentile_ate_first_view(df,'Arrival Delay in Minutes',0,100,10)

percentile_ate_first_view(df,'Arrival Delay in Minutes',90,100,1)

percentile_ate_third_view(df,'Arrival Delay in Minutes')

df[df['Arrival Delay in Minutes']>1000]

def iqr_thresholds(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return lower, upper

# Örnek olarak hesaplayalım
for col in ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']:
    lower, upper = iqr_thresholds(df, col)
    print(f"{col} → Alt sınır: {lower}, Üst sınır: {upper}")

print(df[['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']].isnull().sum())
print(df[['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']].dtypes)

df['Arrival Delay in Minutes'].isnull().sum()
df['Arrival Delay in Minutes'].fillna(value=df['Arrival Delay in Minutes'].median(), inplace=True)
df.isnull().sum()

var = df['Arrival Delay in Minutes'].values
var = np.sort(var, axis=None)
plt.plot(var[-20:-5])

df = pd.read_csv("/content/drive/MyDrive/havayolu/train.csv")  # Yeniden yükleme sonrası
df.dropna(subset=['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes'], inplace=True)

# Gerekirse sayısal türe çevir
for col in ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']:
    df[col] = pd.to_numeric(df[col], errors='coerce')

def removal_outlier(data):
    a = data.shape[0]
    print('{} are the number of rows we have in our original dataframe'.format(a))

    # Belirli sınırları geçen satırları filtreleme
    new_dataframe = data[
        (data['Flight Distance'] < 3995) &
        (data['Departure Delay in Minutes'] < 750) &
        (data['Arrival Delay in Minutes'] < 645)]

    b = new_dataframe.shape[0]
    print(f"Number of outlier: {a-b}")
    print(f"Percentage of data removed:",100 - (b/a) * 100)

    return new_dataframe

# Fonksiyonu veri çerçevesine uygulama
df_final=removal_outlier(df)

df.shape

df_final.head()

"""correlation analysis"""

target_dict = {'neutral or dissatisfied': 0, 'satisfied': 1}
df_final.loc[:, 'satisfaction'] = df_final['satisfaction'].map(target_dict)

import matplotlib.pyplot as plt
import seaborn as sns

# Grafik boyutlarını ve başlığı ayarlama
fig, ax = plt.subplots(figsize=(20, 8))
ax.set_title('Correlation Matrix', fontsize=24, fontweight='bold')

# Renk paletini tanımlama
cmap = sns.diverging_palette(150, 1, as_cmap=True)

# Korelasyon matrisini oluşturma
corr_matrix = df_final[['Flight Distance', 'Inflight wifi service',
                        'Departure/Arrival time convenient', 'Ease of Online booking',
                        'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',
                        'Inflight entertainment', 'On-board service', 'Leg room service',
                        'Baggage handling', 'Checkin service', 'Inflight service',
                        'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'satisfaction']].corr()

# Isı haritası çizme
sns.heatmap(corr_matrix, annot=True, cmap=cmap, ax=ax)

# Grafiği gösterme
plt.show()

# float64 tipindeki sütunları int türüne dönüştür
df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].astype('int')

# Veri çerçevesinin yeni tiplerini kontrol et
print(df.dtypes)

"""Data spliting and scaling"""

x = df[['Gender', 'Age', 'Customer Type', 'Type of Travel', 'Class',
        'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes',
        'Departure/Arrival time convenient', 'Ease of Online booking',
        'Checkin service', 'Online boarding', 'Gate location',
        'On-board service', 'Seat comfort', 'Leg room service', 'Cleanliness',
        'Inflight wifi service', 'Inflight entertainment', 'Food and drink',
        'Inflight service', 'Baggage handling']]

y= df['satisfaction']

from sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test = train_test_split(x,y , test_size= 0.25 , random_state=42)

from sklearn import preprocessing
le=preprocessing.LabelEncoder()
clm=['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']
for x in clm:
    df[x]=le.fit_transform(df[x])

# Veri kümesindeki tüm sütunların veri türlerini kontrol et
print(df.dtypes)

x_train.shape

"""Modeling"""

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score
import warnings
warnings.filterwarnings("ignore")

# Kategorik sütunları dönüştürelim
categorical_columns = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']
le = LabelEncoder()
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

# Özellik ve hedef değişkenleri ayıralım
X = df.drop(columns=['satisfaction'])
y = df['satisfaction']

# Eğitim ve test verilerini ayıralım
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Veriyi ölçekleyelim
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Aşırı öğrenmeyi azaltmak için sadeleştirilmiş modeller
models = {
    "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(n_neighbors=10)
}

# Model sonuçlarını değerlendirelim
for name, model in models.items():
    print(f"📌 {name}")
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred, average='weighted'))
    print(classification_report(y_test, y_pred))

    # Cross-validation sonucu
    cv_scores = cross_val_score(model, X, y, cv=5)
    print("Cross-Validation Accuracy (mean):", cv_scores.mean())
    print("-"*50)

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, f1_score

# Sonuçları tablo halinde kaydetmek için
model_results = []

for name, model in models.items():
    # Modeli eğitim verisiyle eğit
    model.fit(X_train, y_train)

    # Test verisiyle tahmin yap
    y_pred = model.predict(X_test)

    # Model performansını değerlendir
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')

    # Sonuçları kaydet
    model_results.append((name, acc, f1))

# DataFrame oluştur
results_df = pd.DataFrame(model_results, columns=["Model", "Accuracy", "F1 Score"])
results_df.set_index("Model", inplace=True)
results_df.sort_values(by="F1 Score", ascending=False, inplace=True)

# Renk paleti (2 metrik için 2 renk)
colors = ['#8ECFC9', '#FFBE7A']

# Grafik çizimi
ax = results_df.plot(kind="bar", figsize=(10, 6), color=colors)

# Başlık ve görsel ayarlar
plt.title("Modellerin Başarı Karşılaştırması", fontsize=14)
plt.ylabel("Skor")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
import warnings
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)


# Model listesini tanımlayalım
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier()
}

# Her model için confusion matrix çizimi
for name, model in models.items():
    # Modeli eğit
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Confusion matrix hesapla
    cm = confusion_matrix(y_test, y_pred)

    # Görselleştirme
    plt.figure(figsize=(6, 5))  # Grafik boyutunu ayarla
    sns.heatmap(cm, annot=True, fmt="d", cmap="Reds", cbar=False,
                xticklabels=["Hayır", "Evet"], yticklabels=["Hayır", "Evet"])  # Sınıf etiketlerini tanımla
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Tahmin")
    plt.ylabel("Gerçek")
    plt.tight_layout()  # Grafik yerleşimini düzenle
    plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Özelliklerin önem sırasını görselleştireceğiz
for name, model in models.items():
    model.fit(X_train, y_train)

    # Eğer modelin 'feature_importances_' özelliği varsa, bunu alalım
    if hasattr(model, 'feature_importances_'):
        feature_scores = model.feature_importances_
        feature_names = X_train.columns

        # Özelliklerin önem skorlarını DataFrame'e dönüştür
        importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': feature_scores
        })

        # Önemi azalan sırayla sıralıyoruz
        importance_df = importance_df.sort_values(by='Importance', ascending=False)

        # Bar plot ile görselleştiriyoruz
        plt.figure(figsize=(10, 6))
        sns.barplot(x='Importance', y='Feature', data=importance_df, palette='pastel')  # Pastel renk paleti
        plt.title(f'{name} - Özellik Önemleri (Feature Importance)')
        plt.xlabel('Önem Skoru')
        plt.ylabel('Özellik')
        plt.tight_layout()
        plt.show()

!pip install shap

import shap
from xgboost import XGBClassifier  # XGBoost modelini içe aktar

# XGBoost modelini oluştur ve eğit
xgb_model = XGBClassifier(random_state=42)
xgb_model.fit(X_train, y_train)

# SHAP açıklayıcısını oluştur ve SHAP değerlerini hesapla
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# SHAP özet grafiğini çiz
shap.summary_plot(shap_values, X_test)

import numpy as np

# Ortalama SHAP değerlerini hesapla
shap_mean = np.abs(shap_values).mean(axis=0)
feature_names = X_test.columns

# Özellikleri önem sırasına göre sırala
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'SHAP Importance': shap_mean
}).sort_values(by='SHAP Importance', ascending=False)

# Bar grafiğini çiz
plt.figure(figsize=(10, 6))
sns.barplot(x='SHAP Importance', y='Feature', data=importance_df, palette='coolwarm')
plt.title("SHAP - Özellik Önem Grafiği")
plt.tight_layout()
plt.show()

"""normalize features"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

# Hiperparametre aralıkları
rf_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'random_state': [0]
}

knn_params = {
    'n_neighbors': [3, 5, 7],
    'metric': ['euclidean', 'manhattan'],
    'weights': ['uniform', 'distance']
}

dt_params = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'random_state': [0]
}

logistic_params = {
    'C': [0.001, 0.1, 1, 10, 100, 1000],
    'penalty': ['l2'],
    'max_iter': list(range(100, 800, 100)),
    'random_state': [0]
}

# Modelleri oluşturma
rf = RandomForestClassifier()
knn = KNeighborsClassifier()
dt = DecisionTreeClassifier()
log = LogisticRegression()

# GridSearchCV kullanarak her bir modelin en iyi hiperparametrelerini bulma
rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='accuracy')
knn_grid = GridSearchCV(knn, knn_params, cv=3, scoring='accuracy')
dt_grid = GridSearchCV(dt, dt_params, cv=3, scoring='accuracy')
log_grid = GridSearchCV(log, logistic_params, cv=3, scoring='accuracy')

# Modelleri eğitme
rf_grid.fit(X_train, y_train)
knn_grid.fit(X_train, y_train)
dt_grid.fit(X_train, y_train)
log_grid.fit(X_train, y_train)

# En iyi hiperparametreleri ve en iyi skoru yazdırma
print('Random Forest Best Params:', rf_grid.best_params_)
print('Random Forest Best Score:', rf_grid.best_score_)

print('KNN Best Params:', knn_grid.best_params_)
print('KNN Best Score:', knn_grid.best_score_)

print('Decision Tree Best Params:', dt_grid.best_params_)
print('Decision Tree Best Score:', dt_grid.best_score_)

print('Logistic Regression Best Params:', log_grid.best_params_)
print('Logistic Regression Best Score:', log_grid.best_score_)

from sklearn.metrics import accuracy_score, f1_score, classification_report

models = {
    "Random Forest": rf_grid.best_estimator_,
    "KNN": knn_grid.best_estimator_,
    "Decision Tree": dt_grid.best_estimator_,
    "Logistic Regression": log_grid.best_estimator_
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f"\n📌 {name}")
    print(f"Accuracy: {acc}")
    print(f"F1 Score: {f1}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Optimize edilmiş model
best_rf_model = rf_grid.best_estimator_

# Tahminler
y_pred = best_rf_model.predict(X_test)

# Confusion Matrix hesapla
cm = confusion_matrix(y_test, y_pred)

# Confusion Matrix görselleştirmesi
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=["Hayır", "Evet"], yticklabels=["Hayır", "Evet"])
plt.title("Confusion Matrix - GridSearchCV ile Optimize Edilmiş Random Forest")
plt.xlabel("Tahmin")
plt.ylabel("Gerçek")
plt.show()

# 🔁 Gerekli kütüphaneler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix

# 📥 Eğitim ve Test Verilerini Yükle
train_df = pd.read_csv("/content/drive/MyDrive/havayolu/train.csv")
test_df = pd.read_csv("/content/drive/MyDrive/havayolu/test.csv")

# 🎯 Eğitim Verisinde Hedefi Sayısala Çevir
train_df["satisfaction"] = train_df["satisfaction"].apply(lambda x: 1 if x == "satisfied" else 0)

# ❌ Kullanılmayacak Sütunları At
X_train_full = train_df.drop(columns=["satisfaction", "Unnamed: 0", "id"])
y_train = train_df["satisfaction"]
X_test_full = test_df.drop(columns=["satisfaction", "Unnamed: 0", "id"])

# 🔤 Ortak Kategorik Değişkenleri Etiketle
categorical_columns = ["Gender", "Customer Type", "Type of Travel", "Class"]
encoder = LabelEncoder()
for col in categorical_columns:
    all_data = pd.concat([X_train_full[col], X_test_full[col]])
    encoder.fit(all_data)
    X_train_full[col] = encoder.transform(X_train_full[col])
    X_test_full[col] = encoder.transform(X_test_full[col])

# 📏 Sayısal Sütunları Ölçekle
scaler = StandardScaler()
numerical_features = X_train_full.select_dtypes(include='number').columns
X_train_scaled = scaler.fit_transform(X_train_full[numerical_features])
X_test_scaled = scaler.transform(X_test_full[numerical_features])

# 🧠 Modeli Eğit
model = RandomForestClassifier(random_state=42)
model.fit(X_train_scaled, y_train)

# 🎯 Test Setinden Rastgele 100 Yolcu Seç ve Ölçekle
random_100 = X_test_full.sample(100, random_state=42)
random_100_scaled = scaler.transform(random_100[numerical_features])

# 🔍 Memnuniyet Olasılıklarını Tahmin Et
probabilities = model.predict_proba(random_100_scaled)
if probabilities.shape[1] == 1:
    probabilities = np.hstack([1 - probabilities, probabilities])

# 📝 Sonuçları Derle
results = random_100.copy()
results["Memnuniyet Olasılığı (%)"] = (probabilities[:, 1] * 100).round(2)
results["Tahmin"] = np.where(probabilities[:, 1] >= 0.5, "Memnun", "Memnun Değil")

# 📋 100 Yolcu Tahmin Özeti
print("\n🔍 100 Yolcu Memnuniyet Tahminleri:\n")
print(results[["Gender", "Age", "Flight Distance", "Inflight wifi service", "Food and drink", "Seat comfort",
               "Memnuniyet Olasılığı (%)", "Tahmin"]])

# 🌟 En Memnun 5 Yolcu
print("\n🌟 En Yüksek Memnuniyet Olasılığına Sahip 5 Yolcu:\n")
print(results.sort_values("Memnuniyet Olasılığı (%)", ascending=False)[
    ["Gender", "Age", "Flight Distance", "Memnuniyet Olasılığı (%)", "Tahmin"]
].head(5))

# ⚠️ En Memnuniyetsiz 5 Yolcu
print("\n⚠️ En Düşük Memnuniyet Olasılığına Sahip 5 Yolcu:\n")
print(results.sort_values("Memnuniyet Olasılığı (%)")[
    ["Gender", "Age", "Flight Distance", "Memnuniyet Olasılığı (%)", "Tahmin"]
].head(5))

df["satisfaction"] = df["satisfaction"].apply(lambda x: 1 if x == "satisfied" else 0)

# 🎯 Hedef ve Özellikler
X = df.drop(columns=["satisfaction", "Unnamed: 0", "id"])
y = df["satisfaction"]

# 🔤 Kategorik Verileri Sayısala Çevir
categorical_columns = ["Gender", "Type of Travel", "Class", "Customer Type"]
encoder = LabelEncoder()
for col in categorical_columns:
    X[col] = encoder.fit_transform(X[col])

# 🧪 Eğitim-Test Böl
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 📏 Sadece sayısal sütunları ölçekle
numerical_columns = X.select_dtypes(include=["int64", "float64"]).columns
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()
X_train_scaled[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_test_scaled[numerical_columns] = scaler.transform(X_test[numerical_columns])


# 👤 Yeni Yolcu için Tahmin
new_passenger = pd.DataFrame([{
    "Gender": 0,  # Kadın (0), Erkek (1)
    "Age": 29,
    "Flight Distance": 1000,  # Örnek uçuş mesafesi (km cinsinden)
    "Inflight wifi service": 3,
    "Food and drink": 4,
    "Seat comfort": 4,
    "Inflight entertainment": 5,
    "On-board service": 4,
    "Leg room service": 3,
    "Baggage handling": 5,
    "Checkin service": 5,
    "Inflight service": 4,
    "Cleanliness": 4
}])

# Eksik kolon varsa doldur
for col in X.columns:
    if col not in new_passenger.columns:
        new_passenger[col] = 0

# Kolon sırasını düzelt
new_passenger = new_passenger[X.columns]

# Sayısal sütunları ölçekle
new_passenger_scaled = new_passenger.copy()
new_passenger_scaled[numerical_columns] = scaler.transform(new_passenger[numerical_columns])

# Tahmin
prob = model.predict_proba(new_passenger_scaled)[0][1]
tahmin = "Memnun" if prob >= 0.5 else "Memnun Değil"
print(f"\n🧍 Yeni Yolcunun Memnuniyet Olasılığı: %{round(prob*100, 2)} → Tahmin: {tahmin}")

df["satisfaction"] = df["satisfaction"].apply(lambda x: 1 if x == "satisfied" else 0)

# 🎯 Hedef ve Özellikler
X = df.drop(columns=["satisfaction", "Unnamed: 0", "id"])
y = df["satisfaction"]

# 🔤 Kategorik Verileri Sayısala Çevir
categorical_columns = ["Gender", "Type of Travel", "Class", "Customer Type"]
encoder = LabelEncoder()
for col in categorical_columns:
    X[col] = encoder.fit_transform(X[col])

# 🧪 Eğitim-Test Böl
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 📏 Sadece sayısal sütunları ölçekle
numerical_columns = X.select_dtypes(include=["int64", "float64"]).columns
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()
X_train_scaled[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_test_scaled[numerical_columns] = scaler.transform(X_test[numerical_columns])


# 👤 Yeni Yolcu için Tahmin
new_passenger = pd.DataFrame([{
    "Gender": 0,  # Kadın
    "Age": 29,
    "Flight Distance": 2000,
    "Inflight wifi service": 1,
    "Food and drink": 0,
    "Seat comfort": 1,
    "Inflight entertainment": 1,
    "On-board service": 2,
    "Leg room service": 0,
    "Baggage handling": 2,
    "Checkin service": 2,
    "Inflight service": 2,
    "Cleanliness": 0,
    "Type of Travel": 1,  # Personal
    "Class": 0,           # Economy
    "Customer Type": 1    # Loyal
}])

# Eksik kolon varsa doldur
for col in X.columns:
    if col not in new_passenger.columns:
        new_passenger[col] = 0

# Kolon sırasını düzelt
new_passenger = new_passenger[X.columns]

# Sayısal sütunları ölçekle
new_passenger_scaled = new_passenger.copy()
new_passenger_scaled[numerical_columns] = scaler.transform(new_passenger[numerical_columns])

# Tahmin
prob = model.predict_proba(new_passenger_scaled)[0][1]
tahmin = "Memnun" if prob >= 0.5 else "Memnun Değil"
print(f"\n🧍 Yeni Yolcunun Memnuniyet Olasılığı: %{round(prob*100, 2)} → Tahmin: {tahmin}")