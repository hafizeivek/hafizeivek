# -*- coding: utf-8 -*-
"""AirlinePassengerSatisfaction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17PfPFOT_aLvHfuOnqQe2TBWNb8-DGTOa
"""

# SayÄ±sal iÅŸlemler ve dizi iÅŸlemleri iÃ§in
import numpy as np

# Veri analizi ve veri manipÃ¼lasyonu iÃ§in
import pandas as pd

# Grafik Ã§izimleri iÃ§in temel kÃ¼tÃ¼phane
import matplotlib.pyplot as plt

# Ä°statistiksel gÃ¶rselleÅŸtirmeler iÃ§in (Ä±sÄ± haritasÄ±, boxplot, vs.)
import seaborn as sns

# Grafik yerleÅŸimlerini Ã¶zelleÅŸtirmek iÃ§in kullanÄ±lÄ±r (Ã§oklu grafik dÃ¼zeni)
import matplotlib.gridspec as gridspec

# Matplotlib iÃ§in renk haritalarÄ± (colormap) modÃ¼lÃ¼
from matplotlib import cm
import matplotlib.patches as mpatches

from google.colab import drive

# Google Drive'Ä± baÄŸla
drive.mount('/content/drive')

# DosyanÄ±n tam yolu
file_path = '/content/drive/MyDrive/havayolu/train.csv'

# CSV dosyasÄ±nÄ± oku
df = pd.read_csv(file_path)

df.head()  # VarsayÄ±lan olarak ilk 5 satÄ±rÄ± gÃ¶sterir

df.info()  # Veri tipi ve eksik deÄŸerleri gÃ¶sterir

df.shape  # (satÄ±r sayÄ±sÄ±, sÃ¼tun sayÄ±sÄ±)

df.columns

df.describe() # Temel istatistiksel Ã¶zet

# Eksik deÄŸerleri tespit et
missing_values = df.isnull().sum()

# Eksik veri iÃ§eren sÃ¼tunlarÄ± filtreleyerek sadece eksik deÄŸerleri gÃ¶sterelim
missing_values = missing_values[missing_values > 0]

# Sonucu daha dÃ¼zenli gÃ¶rÃ¼ntÃ¼leyelim
print("Eksik DeÄŸer SayÄ±larÄ±:\n")
print(missing_values)

# Eksik veri yÃ¼zdesini hesapla
missing_percentage = (df.isnull().sum() / len(df)) * 100

# Sadece eksik verisi olan sÃ¼tunlarÄ± gÃ¶sterelim
missing_percentage = missing_percentage[missing_percentage > 0]

# Sonucu daha okunaklÄ± hale getirelim
print("Eksik DeÄŸer YÃ¼zdeleri (%):\n")
print(missing_percentage.round(2))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap

# SarÄ±-lacivert Ã¶zel renk paleti
sari_lacivert = ListedColormap(["#f7dc6f", "#1a237e"])  # sarÄ± ve koyu lacivert

plt.figure(figsize=(12, 6))
sns.heatmap(df.isnull(), cmap=sari_lacivert, cbar=False, yticklabels=False)
plt.title("Eksik Verilerin DaÄŸÄ±lÄ±mÄ±", fontsize=14)
plt.show()

df.sample(n=5) # veri setinden 5 rastgele satÄ±r seÃ§me

# SayÄ±sal deÄŸiÅŸkenlerin histogramlarÄ±nÄ± Ã§izme
df.hist(figsize=(12, 8), bins=30,color='#FFE4B5', edgecolor="black")

# BaÅŸlÄ±k ekleme
plt.suptitle("SayÄ±sal DeÄŸiÅŸkenlerin HistogramÄ±", fontsize=14)

# Eksen etiketlerinin aÃ§Ä±larÄ±nÄ± deÄŸiÅŸtirme
plt.xticks(rotation=45)  # x eksenindeki etiketlerin 45 derece dÃ¶ndÃ¼rÃ¼lmesi
plt.yticks(rotation=0)   # y eksenindeki etiketlerin yatay olmasÄ±

# Layout ayarlarÄ±nÄ± yaparak yazÄ±larÄ±n Ã¼st Ã¼ste binmesini engelleme
plt.tight_layout()

# GrafiÄŸi gÃ¶sterme
plt.show()

"""hedef daÄŸÄ±lÄ±mÄ±"""

# Åekli oluÅŸtur
fig = plt.figure(figsize=(22, 6))

# Grid sistemi tanÄ±mla: 1 satÄ±r, 2 sÃ¼tun
grid = gridspec.GridSpec(nrows=1, ncols=2, figure=fig)

# Ä°lk subplot - Ã‡ubuk grafik
ax1 = fig.add_subplot(grid[0, 0])
ax1.set_title('Memnuniyet Durumu DaÄŸÄ±lÄ±mÄ±')
for index, value in enumerate(df['satisfaction'].value_counts()):
    ax1.annotate(value, xy=(index, value), ha='center', va='center', fontsize=15)


# FarklÄ± pastel tonlarÄ± (Set2 renk paleti)
renkler = sns.color_palette("Set2", 2)  # Set2 paleti ile iki renk seÃ§imi

# Ã‡ubuk grafiÄŸi Ã§iz
sns.countplot(x='satisfaction', data=df, ax=ax1, hue='satisfaction', palette=renkler)
ax1.set_xlabel('Yolcu Memnuniyeti')
ax1.set_ylabel('Yolcu SayÄ±sÄ±')

# AÃ§Ä±klama (TÃ¼rkÃ§e legend)
memnun_patch = mpatches.Patch(color=renkler[0], label='TarafsÄ±z veya Memnuniyetsiz')
memnuniyetsiz_patch = mpatches.Patch(color=renkler[1], label='Memnun')
legend = ax1.legend(handles=[memnun_patch, memnuniyetsiz_patch], loc='upper right', frameon=True)
legend.get_frame().set_facecolor('white')
legend.get_frame().set_edgecolor('black')

# Ä°kinci subplot - Pasta grafik
ax2 = fig.add_subplot(grid[0, 1])
ax2.set_title('Memnuniyet OranlarÄ±')

label = list(df['satisfaction'].value_counts().index)
value = list(df['satisfaction'].value_counts().values)
colors = sns.color_palette("Set2", len(label))  # Set2 paleti ile pasta grafiÄŸi iÃ§in renkler

# Pasta grafiÄŸini Ã§iz
ax2.pie(value, labels=label, autopct='%1.1f%%', explode=(0, 0.2), colors=colors, startangle=90)
ax2.axis('equal')  # Daire gibi gÃ¶rÃ¼nsÃ¼n

# GÃ¶ster
plt.tight_layout()
plt.show()

"""yolcu profili"""

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns

# Åekli oluÅŸtur
fig = plt.figure(figsize=(20, 12))
plt.suptitle('Yolcu Profili', weight='bold', fontsize=24)

# Grid sistemi tanÄ±mla: 2 satÄ±r, 2 sÃ¼tun
grid = gridspec.GridSpec(nrows=2, ncols=2, figure=fig)

# Ä°lk subplot - Cinsiyet
ax1 = fig.add_subplot(grid[0, 0])
ax1.set_title('Cinsiyet')

# Etiketler ve deÄŸerler
label = list(df['Gender'].value_counts().index)
value = list(df['Gender'].value_counts().values)

# Pastel renkler
target_colors = ['#FFB3C1', '#A2C2E2']  # Pembe ve mavi pastel tonlarÄ±

# Pasta grafiÄŸi (yarÄ± halka deÄŸil, klasik daire)
ax1.pie(value, labels=label, autopct='%1.1f%%', explode=(0, 0.2), startangle=90, colors=target_colors, wedgeprops={'width': 0.3})
ax1.axis('equal')  # Daire gibi gÃ¶rÃ¼nmesini saÄŸla

# Ä°kinci subplot - MÃ¼ÅŸteri TÃ¼rÃ¼ (Yeni renkler)
ax2 = fig.add_subplot(grid[0, 1])
ax2.set_title('MÃ¼ÅŸteri TÃ¼rÃ¼', fontsize=18)

# Etiketler ve deÄŸerler
label = list(df['Customer Type'].value_counts().index)
value = list(df['Customer Type'].value_counts().values)

# Yeni pastel renkler
target_colors = ['#98FB98', '#8A2BE2']  # Turuncu ve mor pastel tonlarÄ±

# Tam pasta grafiÄŸi (kenarlÄ±k olmadan)
ax2.pie(value, labels=label, autopct='%1.1f%%', explode=(0, 0.2), startangle=90, colors=target_colors)
ax2.axis('equal')

# ÃœÃ§Ã¼ncÃ¼ subplot - Yatay Ã‡ubuk Grafik (Yeni renkler)
ax3 = fig.add_subplot(grid[1, 0])
ax3.set_title('SÄ±nÄ±f', fontsize=18)

# Etiketler ve deÄŸerler
label = list(df['Class'].value_counts().index)
value = list(df['Class'].value_counts().values)

# Yeni pastel renkler
target_colors = ['#FFDAB9', '#E0BBE4', '#57DBDB']  # AÃ§Ä±k yeÅŸil, pembe ve altÄ±n sarÄ±sÄ±

# Yatay Ã§ubuk grafik (kenar Ã§izgileri kaldÄ±rÄ±ldÄ± ve biraz daha aÅŸaÄŸÄ±ya alÄ±ndÄ±)
ax3.barh(label, value, color=target_colors, edgecolor='none')

# Yatay eksen etiketleri
ax3.set_xlabel('Frekans')

# DÃ¶rdÃ¼ncÃ¼ subplot - YaÅŸ DaÄŸÄ±lÄ±mÄ± (KDE grafiÄŸi)
ax4 = fig.add_subplot(grid[1, 1])
ax4.set_title('YaÅŸ DaÄŸÄ±lÄ±mÄ±', fontsize=18)

# KDE grafiÄŸi
sns.kdeplot(df['Age'], ax=ax4, fill=True, color='#FF69B4')

ax4.tick_params(axis='x', labelsize=20)
ax4.tick_params(axis='y', labelsize=20)
ax4.set_xlabel('YaÅŸ', fontsize=20)
ax4.set_ylabel('YoÄŸunluk', fontsize=20)

for spine in ax4.spines.values():
  spine.set_visible(False)

ax4.axvline(df['Age'].mean(),linestyle='--', color='red', label='Ortalama YaÅŸ')
ax4.legend(fontsize=20)

# TÃ¼m grafikleri gÃ¶ster
plt.tight_layout()
plt.show()
# Grafik gÃ¶ster
plt.tight_layout(pad=4.0)  # Bu, grafiÄŸin arasÄ±ndaki boÅŸluÄŸu arttÄ±rÄ±r

# Grafik gÃ¶ster
plt.show()

"""insanlarÄ±n memnuniyet seviyesi"""

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns

# Renk paletleri
renk_paleti = {
    'satisfied': '#A1D490',         # Daha belirgin yeÅŸil
    'neutral or dissatisfied': '#BA89C2'  # Hafif koyu leylak
}
renk_paleti_class = {
    'satisfied': '#FFDAB9',         # Åeftali
    'neutral or dissatisfied': '#FADADD'  # AÃ§Ä±k gÃ¼l rengi
}
renk_paleti_travel = {
    'satisfied': '#ADD8E6',         # Soluk mavi (yeni)
    'neutral or dissatisfied': '#FFB6C1'  # Soluk pembe (yeni)
}
renk_paleti_customer_type = {
    'satisfied': '#90EE90',         # AÃ§Ä±k yeÅŸil
    'neutral or dissatisfied': '#FFCCCB'  # Soluk kÄ±rmÄ±zÄ±
}

# Åekil ve baÅŸlÄ±k
fig = plt.figure(figsize=(30, 18))
plt.suptitle('Yolcu Profili', weight='bold', fontsize=24)

# Grid alanÄ±
grid = gridspec.GridSpec(nrows=2, ncols=2, figure=fig)

# 1. Grafik - Cinsiyet DaÄŸÄ±lÄ±mÄ±
ax1 = fig.add_subplot(grid[0, 0])  # grid[0, :1] yerine grid[0, 0]
ax1.set_title('Cinsiyet DaÄŸÄ±lÄ±mÄ±', fontsize=22)
sns.countplot(x=df['Gender'], hue=df['satisfaction'], ax=ax1, palette=renk_paleti)

# SayÄ± etiketleri
for p in ax1.patches:
    height = p.get_height()
    if height > 0:
        ax1.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax1.get_yaxis().set_visible(False)
for spine in ax1.spines.values():
    spine.set_visible(False)

ax1.tick_params(axis='x', labelsize=15)
ax1.set_xlabel('Cinsiyet', fontsize=20)

# 2. Grafik - SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±
ax2 = fig.add_subplot(grid[0, 1])
ax2.set_title('SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±', fontsize=22)
sns.countplot(x=df['Class'], hue=df['satisfaction'], ax=ax2, palette=renk_paleti_class)

# SayÄ± etiketleri
for p in ax2.patches:
    height = p.get_height()
    if height > 0:
        ax2.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax2.get_yaxis().set_visible(False)
for spine in ax2.spines.values():
    spine.set_visible(False)

ax2.tick_params(axis='x', labelsize=15)
ax2.set_xlabel('SÄ±nÄ±f', fontsize=20)

# 3. Grafik - Seyahat DaÄŸÄ±lÄ±mÄ±
ax3 = fig.add_subplot(grid[1, :1])  # grid[1, :1] seÃ§ilerek 3. grafik alt bÃ¶lÃ¼mde yerleÅŸtirildi
ax3.set_title('Seyahat DaÄŸÄ±lÄ±mÄ±', fontsize=22)

# Seyahat tÃ¼rÃ¼ Ã¼zerine countplot
sns.countplot(x=df['Type of Travel'], hue=df['satisfaction'], ax=ax3, palette=renk_paleti_travel)

# SayÄ± etiketleri
for p in ax3.patches:
    height = p.get_height()
    if height > 0:
        ax3.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax3.get_yaxis().set_visible(False)
for spine in ax3.spines.values():
    spine.set_visible(False)

ax3.tick_params(axis='x', labelsize=15)
ax3.set_xlabel('Seyahat TÃ¼rÃ¼', fontsize=20)

# 4. Grafik - MÃ¼ÅŸteri Tipi ve Tatmin Durumu (Yeni renkler ile)
ax4 = fig.add_subplot(grid[1, 1])  # 4. grafik iÃ§in yer ekleniyor
ax4.set_title('MÃ¼ÅŸteri Tipi ve Tatmin Durumu', fontsize=22)

# Yeni renk paleti ile mÃ¼ÅŸteri tipi ve tatmin durumu Ã¼zerine countplot
sns.countplot(x=df['Customer Type'], hue=df['satisfaction'], ax=ax4, palette=renk_paleti_customer_type)

# SayÄ± etiketleri
for p in ax4.patches:
    height = p.get_height()
    if height > 0:
        ax4.annotate('{:.0f}'.format(height),
                     (p.get_x() + p.get_width()/2, height + 5),
                     ha='center', weight='bold', fontsize=15)

ax4.get_yaxis().set_visible(False)
for spine in ax4.spines.values():
    spine.set_visible(False)

ax4.tick_params(axis='x', labelsize=15)
ax4.set_xlabel('MÃ¼ÅŸteri Tipi', fontsize=20)

# Grafik gÃ¶ster
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Veriyi oku
data = pd.read_csv("/content/drive/MyDrive/havayolu/train.csv")

# 2. Grafik Ã§izimi (renkler Ã¶zelleÅŸtirildi)
with sns.axes_style('white'):
    g = sns.catplot(
        x="Age",
        data=data,
        aspect=3.0,
        kind='count',
        hue='satisfaction',
        palette=['pink', 'skyblue'],
        order=range(5, 80)
    )

    # 3. Eksen etiketleri ve baÅŸlÄ±k
    g.set_ylabels('Yolcu SayÄ±sÄ±')
    g.set_xlabels('YaÅŸ')
    g.fig.suptitle('Yolcu YaÅŸ DaÄŸÄ±lÄ±mÄ± ve Memnuniyet', fontsize=16)

# 4. GrafiÄŸi gÃ¶ster
plt.show()

"""

visualize the ordinal data"""

df.columns

num_var=df.select_dtypes(include=['int']).columns[3:]
num_var

df['Ease of Online booking'].value_counts()

ordinal_dict={
    5: 'Excellent',
    4: 'Very Good',
    3: 'Good',
    2: 'Bad',
    1: 'Very Bad',
    0:'NotÂ Reported'
}
df['Ease of Online booking']=df['Ease of Online booking'].map(ordinal_dict)

df['Ease of Online booking'].value_counts()

def CalPercentage(df, col):
    percent_df = df[col].value_counts(normalize=True).mul(100).reset_index()
    percent_df.columns = [col, 'per']
    return percent_df

CalPercentage(df, 'Ease of Online booking')

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Ordinal dict
ordinal_dict = {
    5: 'Excellent',
    4: 'Very Good',
    3: 'Good',
    2: 'Bad',
    1: 'Very Bad',
    0: 'Not Reported'
}

# YÃ¼zde hesaplama fonksiyonu
def CalPercentage(df, col):
    # Verilen sÃ¼tunun yÃ¼zdesel daÄŸÄ±lÄ±mÄ±nÄ± hesaplama
    percentage = df[col].value_counts(normalize=True) * 100
    df_per = pd.DataFrame({col: percentage.index, 'per': percentage.values})
    return df_per

def Visualization(df, col):
    # Belirtilen sÃ¼tunun yÃ¼zde daÄŸÄ±lÄ±mÄ±nÄ± hesapla
    df_per = CalPercentage(df, col)

    # 1 satÄ±r 2 sÃ¼tundan oluÅŸan bir figÃ¼r (grafik alanÄ±) oluÅŸtur
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 6))

    # GrafiÄŸe genel bir baÅŸlÄ±k ekle
    plt.suptitle(col, fontsize=24, weight='bold')

    # Alt grafikler arasÄ± boÅŸluÄŸu ayarla
    plt.subplots_adjust(hspace=0.9)

    # Ä°lk grafik: Kategorik sÃ¼tunun yÃ¼zdelik daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steren barplot
    pastel_palette = sns.color_palette("pastel", n_colors=len(df_per))  # Pastel renk paleti
    sns.barplot(x=df_per[col], y='per', data=df_per, ax=ax1, palette=pastel_palette)

    # Ä°kinci grafik: AynÄ± sÃ¼tunun memnuniyet durumuna gÃ¶re countplotâ€™u
    sns.countplot(x=col, data=df, hue='satisfaction', ax=ax2, order=ordinal_dict.values(), palette=pastel_palette)

    # Barplot iÃ§in x ekseni etiketlerini ayarla ve dÃ¶ndÃ¼r
    ax1.set_xticklabels(df_per[col], rotation=45)

    # Barplot iÃ§in x ekseni baÅŸlÄ±ÄŸÄ±
    ax1.set_xlabel('Experience', fontsize=20)

    # Barplotâ€™un y eksenini gÃ¶rÃ¼nmez yap
    ax1.get_yaxis().set_visible(False)

    # Countplot iÃ§in x ekseni baÅŸlÄ±ÄŸÄ±
    ax2.set_xlabel(col, fontsize=20)

    # Countplot iÃ§in x ekseni etiketlerini dÃ¶ndÃ¼r
    ax2.set_xticklabels(ordinal_dict.values(), rotation=45)

    # Countplotâ€™un y eksenini gizle
    ax2.get_yaxis().set_visible(False)

    # Her iki grafik iÃ§in kenar Ã§erÃ§evelerini (spine) gizle
    for spine1, spine2 in zip(ax1.spines.values(), ax2.spines.values()):
        spine1.set_visible(False)
        spine2.set_visible(False)

    # Grafiklerin tÃ¼mÃ¼nÃ¼ gÃ¶ster
    plt.show()

Visualization(df, 'Ease of Online booking')

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Ordinal dict
ordinal_dict = {
    5: 'Excellent',
    4: 'Very Good',
    3: 'Good',
    2: 'Bad',
    1: 'Very Bad',
    0: 'Not Reported'
}

# YÃ¼zde hesaplama fonksiyonu (Kolonun her bir deÄŸeri iÃ§in)
def CalPercentage(df, col):
    counts = df[col].value_counts()
    percents = df[col].value_counts(normalize=True) * 100
    df_per = pd.DataFrame({'count': counts, 'per': percents})
    return df_per

def Visualization(df, col):
    # Kolondaki benzersiz deÄŸerleri kontrol et
    print(f"Benzersiz deÄŸerler: {df[col].unique()}")

    # Ordinal dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ yap
    df[col] = df[col].map(ordinal_dict)

    # Kolondaki 'NaN' deÄŸerleri kontrol et
    if df[col].isnull().any():
        print(f"{col} kolonunda eksik (NaN) deÄŸerler var. BunlarÄ± 'Not Reported' olarak iÅŸliyoruz.")
        df[col] = df[col].fillna('Not Reported')

    # Ordinal kategorilerin sÄ±ralanmasÄ±
    df[col] = pd.Categorical(df[col], categories=ordinal_dict.values(), ordered=True)

    # YÃ¼zdelik daÄŸÄ±lÄ±mÄ± hesapla
    df_per = CalPercentage(df, col)

    # 1 satÄ±r 2 sÃ¼tundan oluÅŸan bir figÃ¼r (grafik alanÄ±) oluÅŸtur
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 6))

    # GrafiÄŸe genel bir baÅŸlÄ±k ekle
    plt.suptitle(col, fontsize=24, weight='bold')

    # Alt grafikler arasÄ± boÅŸluÄŸu ayarla
    plt.subplots_adjust(hspace=0.9)

    # Ä°lk grafik: Kategorik sÃ¼tunun yÃ¼zdelik daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steren barplot
    pastel_palette = sns.color_palette("pastel", n_colors=len(df_per))  # Pastel renk paleti

    # Barplotâ€™u metin etiketleri ile oluÅŸtur
    sns.barplot(x=df_per.index, y='per', data=df_per, ax=ax1, palette=pastel_palette)

    # Ä°kinci grafik: AynÄ± sÃ¼tunun memnuniyet durumuna gÃ¶re countplotâ€™u
    pastel_palette = sns.color_palette("pastel", n_colors=2)  # 2 renk

    # Memnuniyet durumuna gÃ¶re countplot Ã§iziyoruz
    sns.countplot(x=col, data=df, hue='satisfaction', ax=ax2,
                  order=ordinal_dict.values(), palette=pastel_palette)

    # Barplot iÃ§in x ekseni etiketlerini ayarla ve dÃ¶ndÃ¼r
    ax1.set_xticklabels(ordinal_dict.values(), rotation=45)

    # Barplot iÃ§in x ekseni baÅŸlÄ±ÄŸÄ±
    ax1.set_xlabel('Experience', fontsize=20)

    # Barplotâ€™un y eksenini gÃ¶rÃ¼nmez yap
    ax1.get_yaxis().set_visible(False)

    # Countplot iÃ§in x ekseni baÅŸlÄ±ÄŸÄ±
    ax2.set_xlabel(col, fontsize=20)

    # Countplot iÃ§in x ekseni etiketlerini dÃ¶ndÃ¼r
    ax2.set_xticklabels(ordinal_dict.values(), rotation=45)

    # Countplotâ€™un y eksenini gizle
    ax2.get_yaxis().set_visible(False)

    # Her iki grafik iÃ§in kenar Ã§erÃ§evelerini (spine) gizle
    for spine1, spine2 in zip(ax1.spines.values(), ax2.spines.values()):
        spine1.set_visible(False)
        spine2.set_visible(False)

    # Grafiklerin tÃ¼mÃ¼nÃ¼ gÃ¶ster
    plt.show()

# Test iÃ§in tek bir sÃ¼tun Ã¼zerinden kontrol edelim
columns = [
    'Inflight wifi service', 'Gate location', 'Food and drink', 'Online boarding',
    'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service',
    'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness'
]

# Her bir sÃ¼tun iÃ§in Visualization fonksiyonunu Ã§alÄ±ÅŸtÄ±rma
for col in columns:
    Visualization(df, col)

"""outlier detection techniques"""

['Flight Distance','Departure Delay in Minutes', 'Arrival Delay in Minutes']

np.percentile(df['Flight Distance'],25)
np.percentile(df['Flight Distance'],75)
iqr=np.percentile(df['Flight Distance'],75)-np.percentile(df['Flight Distance'],25)
upper_limit=np.percentile(df['Flight Distance'],75)+1.5*iqr
lower_limit=np.percentile(df['Flight Distance'],25)-1.5*iqr
print(lower_limit, upper_limit)

import matplotlib.pyplot as plt
import seaborn as sns

# Grafik oluÅŸtur
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
plt.suptitle('Flight Distance Analysis', fontsize=24, weight='bold')

# Box-Plot
ax1.set_title('Box-Plot', fontsize=15)
sns.boxplot(y='Flight Distance', data=df, ax=ax1)
ax1.set_ylabel('Flight Distance', fontsize=20)

# KDE-Plot
ax2.set_title('KDE-Plot', fontsize=15)
sns.kdeplot(x='Flight Distance', data=df, ax=ax2, fill=True, color='#5e597e')

# SÄ±nÄ±r Ã§izgileri
ax2.axvline(x=lower_limit, linestyle='--', color='#06550e', label='Lower Bound')
ax2.axvline(x=upper_limit, linestyle='--', color='#cc1111', label='Upper Bound')
ax2.legend()

# Etiket ve aÃ§Ä±klama
ax2.set_xlabel('Flight Distance', fontsize=20)
ax2.annotate(f'{upper_limit:.0f}',
             xy=(upper_limit, 0.0005),
             arrowprops=dict(arrowstyle='->', color='r', alpha=0.8))

plt.show()

def percentile_ate_first_view(data, col, start, end, jump):
    for i in range(start, end, jump):
        var = data[col].values
        var = np.sort(var, axis=None)
        print("{} percentile value is {}".format(i, var[int(len(var)*(float(i)/100))]))
    print("100 percentile value is ", var[-1])

percentile_ate_first_view(df, 'Flight Distance',0,100,10)

percentile_ate_first_view(df,'Flight Distance',90,100,1)

def percentile_ate_third_view(data, col):
    for i in np.arange(0.0,1.0,0.1):
        var = data[col].values
        var = np.sort(var, axis=None)
        print("{} percentile value is {}".format(99+i, var[int(len(var)*(float(99+i)/100))]))
    print("100 percentile value is ", var[-1])

percentile_ate_third_view(df, 'Flight Distance')

df[df['Flight Distance']>3995]

def OutlierDetection(data, col):
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np

    # IQR hesaplama
    q1 = np.percentile(data[col], 25)
    q3 = np.percentile(data[col], 75)
    iqr = q3 - q1
    lower_bound = q1 - (1.5 * iqr)
    upper_bound = q3 + (1.5 * iqr)

    # Grafik alanlarÄ± oluÅŸtur
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    plt.suptitle(f'{col} Analysis', fontsize=24, weight='bold')

    # Boxplot
    ax1.set_title('Box-Plot', fontsize=15)
    sns.boxplot(y=col, data=data, ax=ax1, flierprops={"marker": "x"})
    ax1.set_ylabel(col, fontsize=20)
    ax1.get_yaxis().set_visible(False)

    # KDE Plot
    ax2.set_title('KDE-Plot', fontsize=15)
    sns.kdeplot(x=data[col], ax=ax2, fill=True, color='#5e597e')
    ax2.axvline(data[col].mean(), linestyle='--', color='#ff4000', label='Mean')
    ax2.axvline(data[col].median(), linestyle='--', color='#4000aa', label='Median')
    ax2.axvline(lower_bound, linestyle='--', color='#06550e', label='Lower Bound')
    ax2.axvline(upper_bound, linestyle='--', color='#1c1111', label='Upper Bound')
    ax2.legend()
    ax2.set_xlabel(col, fontsize=20)
    ax2.annotate(f'{upper_bound:.0f}', xy=(upper_bound, 0.04),
                 arrowprops=dict(arrowstyle='->', color='r', alpha=0.8),
                 fontsize=12)

    plt.tight_layout()
    plt.show()
OutlierDetection(df, 'Departure Delay in Minutes')

percentile_ate_first_view(df,'Departure Delay in Minutes',0,100,10)

percentile_ate_first_view(df,'Departure Delay in Minutes',90,100,1)

percentile_ate_third_view(df,'Departure Delay in Minutes')

var = df['Departure Delay in Minutes'].values
var = np.sort(var, axis=None)
plt.plot(var[-40:-5])

df[df['Departure Delay in Minutes']>750]

OutlierDetection(df, 'Arrival Delay in Minutes')

percentile_ate_first_view(df,'Arrival Delay in Minutes',0,100,10)

percentile_ate_first_view(df,'Arrival Delay in Minutes',90,100,1)

percentile_ate_third_view(df,'Arrival Delay in Minutes')

df[df['Arrival Delay in Minutes']>1000]

def iqr_thresholds(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return lower, upper

# Ã–rnek olarak hesaplayalÄ±m
for col in ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']:
    lower, upper = iqr_thresholds(df, col)
    print(f"{col} â†’ Alt sÄ±nÄ±r: {lower}, Ãœst sÄ±nÄ±r:Â {upper}")

print(df[['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']].isnull().sum())
print(df[['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']].dtypes)

df['Arrival Delay in Minutes'].isnull().sum()
df['Arrival Delay in Minutes'].fillna(value=df['Arrival Delay in Minutes'].median(), inplace=True)
df.isnull().sum()

var = df['Arrival Delay in Minutes'].values
var = np.sort(var, axis=None)
plt.plot(var[-20:-5])

df = pd.read_csv("/content/drive/MyDrive/havayolu/train.csv")  # Yeniden yÃ¼kleme sonrasÄ±
df.dropna(subset=['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes'], inplace=True)

# Gerekirse sayÄ±sal tÃ¼re Ã§evir
for col in ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']:
    df[col] = pd.to_numeric(df[col], errors='coerce')

def removal_outlier(data):
    a = data.shape[0]
    print('{} are the number of rows we have in our original dataframe'.format(a))

    # Belirli sÄ±nÄ±rlarÄ± geÃ§en satÄ±rlarÄ± filtreleme
    new_dataframe = data[
        (data['Flight Distance'] < 3995) &
        (data['Departure Delay in Minutes'] < 750) &
        (data['Arrival Delay in Minutes'] < 645)]

    b = new_dataframe.shape[0]
    print(f"Number of outlier: {a-b}")
    print(f"Percentage of data removed:",100 - (b/a) * 100)

    return new_dataframe

# Fonksiyonu veri Ã§erÃ§evesine uygulama
df_final=removal_outlier(df)

df.shape

df_final.head()

"""correlation analysis"""

target_dict = {'neutral or dissatisfied': 0, 'satisfied': 1}
df_final.loc[:, 'satisfaction'] = df_final['satisfaction'].map(target_dict)

import matplotlib.pyplot as plt
import seaborn as sns

# Grafik boyutlarÄ±nÄ± ve baÅŸlÄ±ÄŸÄ± ayarlama
fig, ax = plt.subplots(figsize=(20, 8))
ax.set_title('Correlation Matrix', fontsize=24, fontweight='bold')

# Renk paletini tanÄ±mlama
cmap = sns.diverging_palette(150, 1, as_cmap=True)

# Korelasyon matrisini oluÅŸturma
corr_matrix = df_final[['Flight Distance', 'Inflight wifi service',
                        'Departure/Arrival time convenient', 'Ease of Online booking',
                        'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',
                        'Inflight entertainment', 'On-board service', 'Leg room service',
                        'Baggage handling', 'Checkin service', 'Inflight service',
                        'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'satisfaction']].corr()

# IsÄ± haritasÄ± Ã§izme
sns.heatmap(corr_matrix, annot=True, cmap=cmap, ax=ax)

# GrafiÄŸi gÃ¶sterme
plt.show()

# float64 tipindeki sÃ¼tunlarÄ± int tÃ¼rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼r
df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].astype('int')

# Veri Ã§erÃ§evesinin yeni tiplerini kontrol et
print(df.dtypes)

"""Data spliting and scaling"""

x = df[['Gender', 'Age', 'Customer Type', 'Type of Travel', 'Class',
        'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes',
        'Departure/Arrival time convenient', 'Ease of Online booking',
        'Checkin service', 'Online boarding', 'Gate location',
        'On-board service', 'Seat comfort', 'Leg room service', 'Cleanliness',
        'Inflight wifi service', 'Inflight entertainment', 'Food and drink',
        'Inflight service', 'Baggage handling']]

y= df['satisfaction']

from sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test = train_test_split(x,y , test_size= 0.25 , random_state=42)

from sklearn import preprocessing
le=preprocessing.LabelEncoder()
clm=['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']
for x in clm:
    df[x]=le.fit_transform(df[x])

# Veri kÃ¼mesindeki tÃ¼m sÃ¼tunlarÄ±n veri tÃ¼rlerini kontrol et
print(df.dtypes)

x_train.shape

"""Modeling"""

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score
import warnings
warnings.filterwarnings("ignore")

# Kategorik sÃ¼tunlarÄ± dÃ¶nÃ¼ÅŸtÃ¼relim
categorical_columns = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']
le = LabelEncoder()
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

# Ã–zellik ve hedef deÄŸiÅŸkenleri ayÄ±ralÄ±m
X = df.drop(columns=['satisfaction'])
y = df['satisfaction']

# EÄŸitim ve test verilerini ayÄ±ralÄ±m
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Veriyi Ã¶lÃ§ekleyelim
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi azaltmak iÃ§in sadeleÅŸtirilmiÅŸ modeller
models = {
    "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(n_neighbors=10)
}

# Model sonuÃ§larÄ±nÄ± deÄŸerlendirelim
for name, model in models.items():
    print(f"ğŸ“Œ {name}")
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred, average='weighted'))
    print(classification_report(y_test, y_pred))

    # Cross-validation sonucu
    cv_scores = cross_val_score(model, X, y, cv=5)
    print("Cross-Validation Accuracy (mean):", cv_scores.mean())
    print("-"*50)

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, f1_score

# SonuÃ§larÄ± tablo halinde kaydetmek iÃ§in
model_results = []

for name, model in models.items():
    # Modeli eÄŸitim verisiyle eÄŸit
    model.fit(X_train, y_train)

    # Test verisiyle tahmin yap
    y_pred = model.predict(X_test)

    # Model performansÄ±nÄ± deÄŸerlendir
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')

    # SonuÃ§larÄ± kaydet
    model_results.append((name, acc, f1))

# DataFrame oluÅŸtur
results_df = pd.DataFrame(model_results, columns=["Model", "Accuracy", "F1 Score"])
results_df.set_index("Model", inplace=True)
results_df.sort_values(by="F1 Score", ascending=False, inplace=True)

# Renk paleti (2 metrik iÃ§in 2 renk)
colors = ['#8ECFC9', '#FFBE7A']

# Grafik Ã§izimi
ax = results_df.plot(kind="bar", figsize=(10, 6), color=colors)

# BaÅŸlÄ±k ve gÃ¶rsel ayarlar
plt.title("Modellerin BaÅŸarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±", fontsize=14)
plt.ylabel("Skor")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
import warnings
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)


# Model listesini tanÄ±mlayalÄ±m
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier()
}

# Her model iÃ§in confusion matrix Ã§izimi
for name, model in models.items():
    # Modeli eÄŸit
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Confusion matrix hesapla
    cm = confusion_matrix(y_test, y_pred)

    # GÃ¶rselleÅŸtirme
    plt.figure(figsize=(6, 5))  # Grafik boyutunu ayarla
    sns.heatmap(cm, annot=True, fmt="d", cmap="Reds", cbar=False,
                xticklabels=["HayÄ±r", "Evet"], yticklabels=["HayÄ±r", "Evet"])  # SÄ±nÄ±f etiketlerini tanÄ±mla
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Tahmin")
    plt.ylabel("GerÃ§ek")
    plt.tight_layout()  # Grafik yerleÅŸimini dÃ¼zenle
    plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Ã–zelliklerin Ã¶nem sÄ±rasÄ±nÄ± gÃ¶rselleÅŸtireceÄŸiz
for name, model in models.items():
    model.fit(X_train, y_train)

    # EÄŸer modelin 'feature_importances_' Ã¶zelliÄŸi varsa, bunu alalÄ±m
    if hasattr(model, 'feature_importances_'):
        feature_scores = model.feature_importances_
        feature_names = X_train.columns

        # Ã–zelliklerin Ã¶nem skorlarÄ±nÄ± DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
        importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': feature_scores
        })

        # Ã–nemi azalan sÄ±rayla sÄ±ralÄ±yoruz
        importance_df = importance_df.sort_values(by='Importance', ascending=False)

        # Bar plot ile gÃ¶rselleÅŸtiriyoruz
        plt.figure(figsize=(10, 6))
        sns.barplot(x='Importance', y='Feature', data=importance_df, palette='pastel')  # Pastel renk paleti
        plt.title(f'{name} - Ã–zellik Ã–nemleri (Feature Importance)')
        plt.xlabel('Ã–nem Skoru')
        plt.ylabel('Ã–zellik')
        plt.tight_layout()
        plt.show()

!pip install shap

import shap
from xgboost import XGBClassifier  # XGBoost modelini iÃ§e aktar

# XGBoost modelini oluÅŸtur ve eÄŸit
xgb_model = XGBClassifier(random_state=42)
xgb_model.fit(X_train, y_train)

# SHAP aÃ§Ä±klayÄ±cÄ±sÄ±nÄ± oluÅŸtur ve SHAP deÄŸerlerini hesapla
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# SHAP Ã¶zet grafiÄŸini Ã§iz
shap.summary_plot(shap_values, X_test)

import numpy as np

# Ortalama SHAP deÄŸerlerini hesapla
shap_mean = np.abs(shap_values).mean(axis=0)
feature_names = X_test.columns

# Ã–zellikleri Ã¶nem sÄ±rasÄ±na gÃ¶re sÄ±rala
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'SHAP Importance': shap_mean
}).sort_values(by='SHAP Importance', ascending=False)

# Bar grafiÄŸini Ã§iz
plt.figure(figsize=(10, 6))
sns.barplot(x='SHAP Importance', y='Feature', data=importance_df, palette='coolwarm')
plt.title("SHAP - Ã–zellik Ã–nem GrafiÄŸi")
plt.tight_layout()
plt.show()

"""normalize features"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

# Hiperparametre aralÄ±klarÄ±
rf_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'random_state': [0]
}

knn_params = {
    'n_neighbors': [3, 5, 7],
    'metric': ['euclidean', 'manhattan'],
    'weights': ['uniform', 'distance']
}

dt_params = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'random_state': [0]
}

logistic_params = {
    'C': [0.001, 0.1, 1, 10, 100, 1000],
    'penalty': ['l2'],
    'max_iter': list(range(100, 800, 100)),
    'random_state': [0]
}

# Modelleri oluÅŸturma
rf = RandomForestClassifier()
knn = KNeighborsClassifier()
dt = DecisionTreeClassifier()
log = LogisticRegression()

# GridSearchCV kullanarak her bir modelin en iyi hiperparametrelerini bulma
rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='accuracy')
knn_grid = GridSearchCV(knn, knn_params, cv=3, scoring='accuracy')
dt_grid = GridSearchCV(dt, dt_params, cv=3, scoring='accuracy')
log_grid = GridSearchCV(log, logistic_params, cv=3, scoring='accuracy')

# Modelleri eÄŸitme
rf_grid.fit(X_train, y_train)
knn_grid.fit(X_train, y_train)
dt_grid.fit(X_train, y_train)
log_grid.fit(X_train, y_train)

# En iyi hiperparametreleri ve en iyi skoru yazdÄ±rma
print('Random Forest Best Params:', rf_grid.best_params_)
print('Random Forest Best Score:', rf_grid.best_score_)

print('KNN Best Params:', knn_grid.best_params_)
print('KNN Best Score:', knn_grid.best_score_)

print('Decision Tree Best Params:', dt_grid.best_params_)
print('Decision Tree Best Score:', dt_grid.best_score_)

print('Logistic Regression Best Params:', log_grid.best_params_)
print('Logistic Regression Best Score:', log_grid.best_score_)

from sklearn.metrics import accuracy_score, f1_score, classification_report

models = {
    "Random Forest": rf_grid.best_estimator_,
    "KNN": knn_grid.best_estimator_,
    "Decision Tree": dt_grid.best_estimator_,
    "Logistic Regression": log_grid.best_estimator_
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f"\nğŸ“Œ {name}")
    print(f"Accuracy: {acc}")
    print(f"F1 Score: {f1}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Optimize edilmiÅŸ model
best_rf_model = rf_grid.best_estimator_

# Tahminler
y_pred = best_rf_model.predict(X_test)

# Confusion Matrix hesapla
cm = confusion_matrix(y_test, y_pred)

# Confusion Matrix gÃ¶rselleÅŸtirmesi
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=["HayÄ±r", "Evet"], yticklabels=["HayÄ±r", "Evet"])
plt.title("Confusion Matrix - GridSearchCV ile Optimize EdilmiÅŸ Random Forest")
plt.xlabel("Tahmin")
plt.ylabel("GerÃ§ek")
plt.show()

# ğŸ” Gerekli kÃ¼tÃ¼phaneler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix

# ğŸ“¥ EÄŸitim ve Test Verilerini YÃ¼kle
train_df = pd.read_csv("/content/drive/MyDrive/havayolu/train.csv")
test_df = pd.read_csv("/content/drive/MyDrive/havayolu/test.csv")

# ğŸ¯ EÄŸitim Verisinde Hedefi SayÄ±sala Ã‡evir
train_df["satisfaction"] = train_df["satisfaction"].apply(lambda x: 1 if x == "satisfied" else 0)

# âŒ KullanÄ±lmayacak SÃ¼tunlarÄ± At
X_train_full = train_df.drop(columns=["satisfaction", "Unnamed: 0", "id"])
y_train = train_df["satisfaction"]
X_test_full = test_df.drop(columns=["satisfaction", "Unnamed: 0", "id"])

# ğŸ”¤ Ortak Kategorik DeÄŸiÅŸkenleri Etiketle
categorical_columns = ["Gender", "Customer Type", "Type of Travel", "Class"]
encoder = LabelEncoder()
for col in categorical_columns:
    all_data = pd.concat([X_train_full[col], X_test_full[col]])
    encoder.fit(all_data)
    X_train_full[col] = encoder.transform(X_train_full[col])
    X_test_full[col] = encoder.transform(X_test_full[col])

# ğŸ“ SayÄ±sal SÃ¼tunlarÄ± Ã–lÃ§ekle
scaler = StandardScaler()
numerical_features = X_train_full.select_dtypes(include='number').columns
X_train_scaled = scaler.fit_transform(X_train_full[numerical_features])
X_test_scaled = scaler.transform(X_test_full[numerical_features])

# ğŸ§  Modeli EÄŸit
model = RandomForestClassifier(random_state=42)
model.fit(X_train_scaled, y_train)

# ğŸ¯ Test Setinden Rastgele 100 Yolcu SeÃ§ ve Ã–lÃ§ekle
random_100 = X_test_full.sample(100, random_state=42)
random_100_scaled = scaler.transform(random_100[numerical_features])

# ğŸ” Memnuniyet OlasÄ±lÄ±klarÄ±nÄ± Tahmin Et
probabilities = model.predict_proba(random_100_scaled)
if probabilities.shape[1] == 1:
    probabilities = np.hstack([1 - probabilities, probabilities])

# ğŸ“ SonuÃ§larÄ± Derle
results = random_100.copy()
results["Memnuniyet OlasÄ±lÄ±ÄŸÄ± (%)"] = (probabilities[:, 1] * 100).round(2)
results["Tahmin"] = np.where(probabilities[:, 1] >= 0.5, "Memnun", "Memnun DeÄŸil")

# ğŸ“‹ 100 Yolcu Tahmin Ã–zeti
print("\nğŸ” 100 Yolcu Memnuniyet Tahminleri:\n")
print(results[["Gender", "Age", "Flight Distance", "Inflight wifi service", "Food and drink", "Seat comfort",
               "Memnuniyet OlasÄ±lÄ±ÄŸÄ± (%)", "Tahmin"]])

# ğŸŒŸ En Memnun 5 Yolcu
print("\nğŸŒŸ En YÃ¼ksek Memnuniyet OlasÄ±lÄ±ÄŸÄ±na Sahip 5 Yolcu:\n")
print(results.sort_values("Memnuniyet OlasÄ±lÄ±ÄŸÄ± (%)", ascending=False)[
    ["Gender", "Age", "Flight Distance", "Memnuniyet OlasÄ±lÄ±ÄŸÄ± (%)", "Tahmin"]
].head(5))

# âš ï¸ En Memnuniyetsiz 5 Yolcu
print("\nâš ï¸ En DÃ¼ÅŸÃ¼k Memnuniyet OlasÄ±lÄ±ÄŸÄ±na Sahip 5 Yolcu:\n")
print(results.sort_values("Memnuniyet OlasÄ±lÄ±ÄŸÄ± (%)")[
    ["Gender", "Age", "Flight Distance", "Memnuniyet OlasÄ±lÄ±ÄŸÄ± (%)", "Tahmin"]
].head(5))

df["satisfaction"] = df["satisfaction"].apply(lambda x: 1 if x == "satisfied" else 0)

# ğŸ¯ Hedef ve Ã–zellikler
X = df.drop(columns=["satisfaction", "Unnamed: 0", "id"])
y = df["satisfaction"]

# ğŸ”¤ Kategorik Verileri SayÄ±sala Ã‡evir
categorical_columns = ["Gender", "Type of Travel", "Class", "Customer Type"]
encoder = LabelEncoder()
for col in categorical_columns:
    X[col] = encoder.fit_transform(X[col])

# ğŸ§ª EÄŸitim-Test BÃ¶l
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ğŸ“ Sadece sayÄ±sal sÃ¼tunlarÄ± Ã¶lÃ§ekle
numerical_columns = X.select_dtypes(include=["int64", "float64"]).columns
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()
X_train_scaled[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_test_scaled[numerical_columns] = scaler.transform(X_test[numerical_columns])


# ğŸ‘¤ Yeni Yolcu iÃ§in Tahmin
new_passenger = pd.DataFrame([{
    "Gender": 0,  # KadÄ±n (0), Erkek (1)
    "Age": 29,
    "Flight Distance": 1000,  # Ã–rnek uÃ§uÅŸ mesafesi (km cinsinden)
    "Inflight wifi service": 3,
    "Food and drink": 4,
    "Seat comfort": 4,
    "Inflight entertainment": 5,
    "On-board service": 4,
    "Leg room service": 3,
    "Baggage handling": 5,
    "Checkin service": 5,
    "Inflight service": 4,
    "Cleanliness": 4
}])

# Eksik kolon varsa doldur
for col in X.columns:
    if col not in new_passenger.columns:
        new_passenger[col] = 0

# Kolon sÄ±rasÄ±nÄ± dÃ¼zelt
new_passenger = new_passenger[X.columns]

# SayÄ±sal sÃ¼tunlarÄ± Ã¶lÃ§ekle
new_passenger_scaled = new_passenger.copy()
new_passenger_scaled[numerical_columns] = scaler.transform(new_passenger[numerical_columns])

# Tahmin
prob = model.predict_proba(new_passenger_scaled)[0][1]
tahmin = "Memnun" if prob >= 0.5 else "Memnun DeÄŸil"
print(f"\nğŸ§ Yeni Yolcunun Memnuniyet OlasÄ±lÄ±ÄŸÄ±: %{round(prob*100, 2)} â†’ Tahmin: {tahmin}")

df["satisfaction"] = df["satisfaction"].apply(lambda x: 1 if x == "satisfied" else 0)

# ğŸ¯ Hedef ve Ã–zellikler
X = df.drop(columns=["satisfaction", "Unnamed: 0", "id"])
y = df["satisfaction"]

# ğŸ”¤ Kategorik Verileri SayÄ±sala Ã‡evir
categorical_columns = ["Gender", "Type of Travel", "Class", "Customer Type"]
encoder = LabelEncoder()
for col in categorical_columns:
    X[col] = encoder.fit_transform(X[col])

# ğŸ§ª EÄŸitim-Test BÃ¶l
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ğŸ“ Sadece sayÄ±sal sÃ¼tunlarÄ± Ã¶lÃ§ekle
numerical_columns = X.select_dtypes(include=["int64", "float64"]).columns
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()
X_train_scaled[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_test_scaled[numerical_columns] = scaler.transform(X_test[numerical_columns])


# ğŸ‘¤ Yeni Yolcu iÃ§in Tahmin
new_passenger = pd.DataFrame([{
    "Gender": 0,  # KadÄ±n
    "Age": 29,
    "Flight Distance": 2000,
    "Inflight wifi service": 1,
    "Food and drink": 0,
    "Seat comfort": 1,
    "Inflight entertainment": 1,
    "On-board service": 2,
    "Leg room service": 0,
    "Baggage handling": 2,
    "Checkin service": 2,
    "Inflight service": 2,
    "Cleanliness": 0,
    "Type of Travel": 1,  # Personal
    "Class": 0,           # Economy
    "Customer Type": 1    # Loyal
}])

# Eksik kolon varsa doldur
for col in X.columns:
    if col not in new_passenger.columns:
        new_passenger[col] = 0

# Kolon sÄ±rasÄ±nÄ± dÃ¼zelt
new_passenger = new_passenger[X.columns]

# SayÄ±sal sÃ¼tunlarÄ± Ã¶lÃ§ekle
new_passenger_scaled = new_passenger.copy()
new_passenger_scaled[numerical_columns] = scaler.transform(new_passenger[numerical_columns])

# Tahmin
prob = model.predict_proba(new_passenger_scaled)[0][1]
tahmin = "Memnun" if prob >= 0.5 else "Memnun DeÄŸil"
print(f"\nğŸ§ Yeni Yolcunun Memnuniyet OlasÄ±lÄ±ÄŸÄ±: %{round(prob*100, 2)} â†’ Tahmin: {tahmin}")